{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qh4gaVUsBrBo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qh4gaVUsBrBo",
    "outputId": "6a633b9a-7b84-4306-cf82-1b78dc6c2b36"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow_text\n",
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pE7jnLVDCO8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pE7jnLVDCO8b",
    "outputId": "fdff91a1-531c-48ca-a490-0459b0803949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan  9 18:31:06 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   54C    P0    25W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ade38acb-1365-4367-ae88-da1511dfe59d",
   "metadata": {
    "id": "ade38acb-1365-4367-ae88-da1511dfe59d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import contractions\n",
    "import pickle\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from keras.layers import Input,Dropout,Dense, LSTM, TextVectorization, Embedding\n",
    "from keras import Model, Sequential\n",
    "from  keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3232e4-b606-49c7-ab00-cbe5ffcd0fa1",
   "metadata": {},
   "source": [
    "# Modeling and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9ca477f-88b1-4a56-a9a8-0460451f54b6",
   "metadata": {
    "id": "f9ca477f-88b1-4a56-a9a8-0460451f54b6"
   },
   "outputs": [],
   "source": [
    "#read in file\n",
    "wine = pd.read_csv('data/2022_winemag_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0709ddc-0222-40d0-965c-a4052b7bd1ff",
   "metadata": {
    "id": "a0709ddc-0222-40d0-965c-a4052b7bd1ff"
   },
   "source": [
    "### Model features and targets preperation\n",
    "- For modeling, I will only be using the sommelier's reviews to predict wine variety. Seen in the wine description EDA, TDIF vocabularies and Word2Vec word similarities show significant information and are capable of being a predictive feature for modeling variety. Because of the large range of varieties, I will simplify the target variables based on specific grape varieties, excluding blends, and only chosing varieties that have atleast 700 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36ade7f6-46cf-4c8b-b3a1-2b5fe7be57d1",
   "metadata": {
    "id": "36ade7f6-46cf-4c8b-b3a1-2b5fe7be57d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinot Noir            2458\n",
      "Chardonnay            1912\n",
      "Cabernet Sauvignon    1832\n",
      "Gamay                  907\n",
      "Sangiovese             887\n",
      "Sauvignon Blanc        882\n",
      "Portuguese Red         861\n",
      "Rosé                   825\n",
      "Syrah                  700\n",
      "Name: variety, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#feature and labels from the dataset\n",
    "model_df = wine[['description','variety']]\n",
    "\n",
    "#Drop any varieties that contains a blend, better for classifying specific grapesa\n",
    "model_df = model_df[~model_df['variety'].str.contains(\"Blend\")]\n",
    "\n",
    "#creating a list of the varieties with sufficient data \n",
    "variety_700 = model_df['variety'].value_counts()[model_df['variety'].value_counts() >= 700].keys()\n",
    "\n",
    "#condensing data to only contain those varieties \n",
    "condensed_model_df = model_df[model_df['variety'].isin(variety_700)]\n",
    "print(condensed_model_df.variety.value_counts())\n",
    "\n",
    "#creating a class output variable for modeling later on\n",
    "class_outputs = len(condensed_model_df['variety'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9556a5-bac0-4160-b1bc-73922bb73cf7",
   "metadata": {
    "id": "6e9556a5-bac0-4160-b1bc-73922bb73cf7"
   },
   "source": [
    "- The most popular wine varieties have far more wine reviews than the others. To help with the classification modeling, the target labels will undersampled to match the minority group total. This equalization will remove any skew the modelings that may occur in favor of the majority class. Imblearn library makes this easy with the RandomUnderSampler object. After undersampling, the target labels will be encoded in preperation for modeling with Sklearn's Label Encoder Object. The encoded varieties will be saved to a dictionary for decoding after modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "775734a1-a425-407b-9b48-27d972281390",
   "metadata": {
    "id": "775734a1-a425-407b-9b48-27d972281390"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoded_variety  variety           \n",
       "0                Cabernet Sauvignon    700\n",
       "1                Chardonnay            700\n",
       "2                Gamay                 700\n",
       "3                Pinot Noir            700\n",
       "4                Portuguese Red        700\n",
       "5                Rosé                  700\n",
       "6                Sangiovese            700\n",
       "7                Sauvignon Blanc       700\n",
       "8                Syrah                 700\n",
       "Name: variety, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#undersample based on the minority group ('Syrah')\n",
    "undersample = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "#fit to the data\n",
    "under_sampled = undersample.fit_resample(condensed_model_df[['description']],condensed_model_df[['variety']])\n",
    "\n",
    "#merge the undersampled data into one \n",
    "under_sampled_df = pd.merge(left = under_sampled[0],right = under_sampled[1],right_index=True,left_index=True)\n",
    "\n",
    "#instantiates label encoder \n",
    "le = LabelEncoder()\n",
    "\n",
    "#create new target column for encoded variable\n",
    "under_sampled_df['encoded_variety'] = le.fit_transform(under_sampled_df['variety'])\n",
    "\n",
    "#decoding dictionary for predictions\n",
    "mapping = dict(zip(range(len(le.classes_)),le.classes_))\n",
    "\n",
    "#show new value counts for each target variable\n",
    "under_sampled_df.groupby('encoded_variety')['variety'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228f898-4f11-4419-bee2-2c617b22a017",
   "metadata": {
    "id": "3228f898-4f11-4419-bee2-2c617b22a017"
   },
   "source": [
    "### Standardize Text\n",
    "- The description for each wine will need to be standardized again for baseline modeling with Naive Bayes. The text will be striped of any punctuation, numbers, lowered in case, and tonkenized. Then the text will be put through TFID vectorizor before the naive bayes model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4ed0f5eb-a540-4ae5-814f-3ea524535d35",
   "metadata": {
    "id": "4ed0f5eb-a540-4ae5-814f-3ea524535d35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words: 9499\n",
      "Max Length: 671\n"
     ]
    }
   ],
   "source": [
    "#standardization function\n",
    "def standardization(input_data):\n",
    "    regex = RegexpTokenizer(r'[\\w\\'\\']+')\n",
    "\n",
    "    conctract = contractions.fix(input_data)\n",
    "    no_num = re.sub(r'\\d+', '', conctract)\n",
    "    tokens = regex.tokenize(no_num.lower())\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "#save formated text to new column \n",
    "under_sampled_df['text'] = under_sampled_df['description'].apply(standardization)\n",
    "\n",
    "#Total amount of unique()\n",
    "raw_text = ''\n",
    "for text in under_sampled_df['text']:\n",
    "    raw_text += text\n",
    "word_count = len(set(raw_text.split()))\n",
    "print('Unique words:',word_count)\n",
    "print('Max Length:',max(under_sampled_df['text'].apply(len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee45394-595f-4af3-b4af-7d6ffc31b3c3",
   "metadata": {
    "id": "0ee45394-595f-4af3-b4af-7d6ffc31b3c3"
   },
   "source": [
    "### Train/Test\n",
    "- Split the data 75/25 and stratify target variables so that there is equal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "fc2097ce-0fc9-413a-b063-7bbb10f80efa",
   "metadata": {
    "id": "fc2097ce-0fc9-413a-b063-7bbb10f80efa"
   },
   "outputs": [],
   "source": [
    "#Split variables to x and y\n",
    "X = under_sampled_df[['text']]\n",
    "y = under_sampled_df['encoded_variety']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a51df-277a-4741-8369-e91e3de718f5",
   "metadata": {
    "id": "ef1a51df-277a-4741-8369-e91e3de718f5"
   },
   "source": [
    "### Multinomial Naive Bayes\n",
    " - The basic model will be Multinomial Naive Bayes. This model uses Bayes Theorm of Probability which calculates the probability of an event occurring based on the prior knowledge of conditions. This modeling type is typically used for NLP classification due for simple, fast, and efficient computing power. This will be compared to Neural Nets to show if a larger pre-trained model will improve classification accuracy.\n",
    " - The Term Frequency Inverse Document Frequency (TFID) vectorizer to transform text into a vector that can actually be interpretted by the model. The text is counted, indexed, and based on the frequency and inverse document frequency of the word over the entire range of documents, is converted to a vector. All stop words are removed since these tend to not relate to the important context of each document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0dace49e-accc-498b-8825-e35283e65745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075132275132275\n",
      "0.819047619047619\n"
     ]
    }
   ],
   "source": [
    "#vectorizer and model used in the grid search\n",
    "tfid = TfidfVectorizer(stop_words='english',max_features=5000,ngram_range=(1, 3),max_df=.6)\n",
    "mn = MultinomialNB()\n",
    "\n",
    "\n",
    "#params for gridsearch\n",
    "params = {\n",
    "          'mn__alpha':[.3,.9,1]\n",
    "         }\n",
    "         \n",
    "#put put everthing together in a pipeline\n",
    "pipe_nb = Pipeline([\n",
    "    ('tfid',tfid),\n",
    "    ('mn',mn)])\n",
    "\n",
    "#run gridsearch with pipe and param grid\n",
    "grid_nb = GridSearchCV(\n",
    "    estimator=pipe_nb, \n",
    "    param_grid=params,\n",
    "    scoring='accuracy',\n",
    "    cv = 5,\n",
    "    n_jobs=-1)\n",
    "\n",
    "#fit the model to the text only data because of the MultinomialNB can't have negative numbers\n",
    "grid_nb.fit(X_train,y_train)\n",
    "\n",
    "#print best params,accuracy scores,and confusion matrix\n",
    "print(grid_nb.score(X_train,y_train))\n",
    "print(grid_nb.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d1677-bc03-4fe8-9c76-353824966e42",
   "metadata": {
    "id": "lTLZAWF8lpl4",
    "tags": []
   },
   "source": [
    "### Sequential Model with Embedding\n",
    "- In this model, text will again be vectorized but instead with Keras.text and a sequential recurrent neural net model. Each description is standardized (lowercased and punctuation removed), split,  recombined as ngrams, indexed, and vectorized. This model is strictly bound by the words within the data corpus. This is limited in the scope and contextual relation. \n",
    "- Once vectorized, the embedding layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. Then the vectors are fed through an LSTM layer, Dense, and Dropout layers. This model under performs to the Naive Bayes due to the limited context of the vocabulary and vector relations. Using the BERT model is intended to help by adding a larger and more complex vocabulary in terms of vocabulary depth, word relationships, and the resulting vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "3df66884-0d97-47ee-8008-a83caa8c2e74",
   "metadata": {
    "id": "3df66884-0d97-47ee-8008-a83caa8c2e74"
   },
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(max_tokens=6000,output_sequence_length=500)\n",
    "vectorize_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "4d68fafb-e6c2-41c5-99ee-5a09189507ac",
   "metadata": {
    "id": "4d68fafb-e6c2-41c5-99ee-5a09189507ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_12 (Text  (None, 500)              0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_21 (Embedding)    (None, 500, 64)           383104    \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " output (Dense)              (None, 9)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421,481\n",
      "Trainable params: 421,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectorize_layer)\n",
    "model.add(Embedding(input_dim = len(vectorize_layer.get_vocabulary()),\n",
    "                    output_dim = 64,\n",
    "                    mask_zero = True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(class_outputs, activation='softmax',name='output'))\n",
    "\n",
    "#model summary\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "AAbznADwobqB",
   "metadata": {
    "id": "AAbznADwobqB"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "2H8KH_FtskZn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2H8KH_FtskZn",
    "outputId": "e4350b62-e6ef-48c2-a1b7-1bb5c94045e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 21s 537ms/step - loss: 2.1865 - accuracy: 0.1566 - val_loss: 2.1509 - val_accuracy: 0.2138\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 15s 487ms/step - loss: 1.9757 - accuracy: 0.2246 - val_loss: 1.7741 - val_accuracy: 0.2762\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 15s 496ms/step - loss: 1.6325 - accuracy: 0.3622 - val_loss: 1.4734 - val_accuracy: 0.4180\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 14s 475ms/step - loss: 1.3065 - accuracy: 0.4479 - val_loss: 1.2430 - val_accuracy: 0.5376\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 15s 486ms/step - loss: 1.1087 - accuracy: 0.5288 - val_loss: 1.1607 - val_accuracy: 0.5418\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 15s 488ms/step - loss: 0.9236 - accuracy: 0.6233 - val_loss: 1.0640 - val_accuracy: 0.6042\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 14s 473ms/step - loss: 0.8057 - accuracy: 0.6767 - val_loss: 0.9870 - val_accuracy: 0.6825\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 14s 483ms/step - loss: 0.6532 - accuracy: 0.7487 - val_loss: 0.9792 - val_accuracy: 0.6889\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 14s 476ms/step - loss: 0.5414 - accuracy: 0.7997 - val_loss: 1.0704 - val_accuracy: 0.6825\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 15s 487ms/step - loss: 0.4888 - accuracy: 0.8241 - val_loss: 1.0423 - val_accuracy: 0.7026\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,validation_split=.2,batch_size = 128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f22aa70-5199-493a-8174-d11df68d6e99",
   "metadata": {
    "id": "6f22aa70-5199-493a-8174-d11df68d6e99"
   },
   "source": [
    "### Bert Pre-Trained Model\n",
    "- BERT, Bidirectional Encoder Representations from Transformers, is Google's pretrained transformer model that has a vareitiy of NLP applications. Trained on over 3,300 million words it is better equiped to understand contextial relationships during vectorization. Using raw text as input, BERT's transformer will pre-process and encode through its pre-trained library. This model has been nicely ported in Keras for use as fine-tuned model like classifying wine varieties. \n",
    "- To further increase the performance of the model, an optimizier scheduler was used to decay learning rate of the model over the training time. This is done using the PolynomialDecay and applying through the Adam optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0ab9d-5ace-417c-93f8-57789fd8b188",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4e0ab9d-5ace-417c-93f8-57789fd8b188",
    "outputId": "7eb95019-af1f-41e6-e267-3a937ec1d7ad"
   },
   "outputs": [],
   "source": [
    "#Keras hub URL that contain both the BERT preprocessing moduel and connected encoding model. \n",
    "preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "\n",
    "#create the BERT layers\n",
    "bert_preprocess = hub.KerasLayer(preprocess_url, name = 'preprocessing')\n",
    "bert_encoder = hub.KerasLayer(encoder_url,trainable=True, name ='Bert_encoding')\n",
    "\n",
    "#test out encoding and preprocessing\n",
    "# def get_sentence_embeding(text):\n",
    "#     preprocess_test = bert_preprocess([text])\n",
    "#     return bert_encoder(preprocess_test)['pooled_output']\n",
    "\n",
    "# x = get_sentence_embeding(X_train.iloc[200]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dc63974d-39ce-4be8-9e2d-66e15a017af1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc63974d-39ce-4be8-9e2d-66e15a017af1",
    "outputId": "f201338d-39f2-4ea2-9913-c2204f3cbbcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)     {'input_type_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " Bert_encoding (KerasLayer)     {'pooled_output': (  109482241   ['preprocessing[2][0]',          \n",
      "                                None, 768),                       'preprocessing[2][1]',          \n",
      "                                 'encoder_outputs':               'preprocessing[2][2]']          \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'default': (None,                                                \n",
      "                                768)}                                                             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 768)          0           ['Bert_encoding[2][13]']         \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16)           12304       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 9)            153         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,494,698\n",
      "Trainable params: 109,494,697\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#bert layers\n",
    "text_input = Input(shape=(),dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "#neural net layers\n",
    "dropout = Dropout(.4)(outputs['pooled_output'])\n",
    "dense = Dense(16,activation='relu')(dropout)\n",
    "dense = Dense(class_outputs, activation='softmax',name='output')(dense)\n",
    "\n",
    "#construct mode\n",
    "model = Model(inputs = [text_input], outputs=[dense])\n",
    "\n",
    "#model summary\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aCq0kZ8CHnJm",
   "metadata": {
    "id": "aCq0kZ8CHnJm"
   },
   "outputs": [],
   "source": [
    "#create a polyninnomal decay(in this case linear decay) for learning rate over the entire training \n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "num_train_steps = (len(y_train) * num_epochs)\n",
    "lr_scheduler = PolynomialDecay(initial_learning_rate=5e-5,\n",
    "                               end_learning_rate = 0.,\n",
    "                               decay_steps = num_train_steps)\n",
    "\n",
    "#apply the scheduler to the Adam Optimizier\n",
    "opt = Adam(learning_rate=lr_scheduler)\n",
    "\n",
    "#complie the model with the newly optimizer variable\n",
    "model.compile(optimizer=opt,\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "747dd70c-b7b2-4c0e-82ab-bb1bcc73cbd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "747dd70c-b7b2-4c0e-82ab-bb1bcc73cbd3",
    "outputId": "32ec0431-7a97-4b42-9a9f-bf3cb1a6f9f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "119/119 [==============================] - 144s 913ms/step - loss: 0.9178 - accuracy: 0.7230 - val_loss: 0.4225 - val_accuracy: 0.8794\n",
      "Epoch 2/5\n",
      "119/119 [==============================] - 107s 903ms/step - loss: 0.3866 - accuracy: 0.8878 - val_loss: 0.3717 - val_accuracy: 0.8952\n",
      "Epoch 3/5\n",
      "119/119 [==============================] - 107s 902ms/step - loss: 0.2200 - accuracy: 0.9421 - val_loss: 0.4149 - val_accuracy: 0.8847\n",
      "Epoch 4/5\n",
      "119/119 [==============================] - 108s 905ms/step - loss: 0.1471 - accuracy: 0.9577 - val_loss: 0.4214 - val_accuracy: 0.8899\n",
      "Epoch 5/5\n",
      "119/119 [==============================] - 107s 901ms/step - loss: 0.1119 - accuracy: 0.9688 - val_loss: 0.4412 - val_accuracy: 0.8899\n"
     ]
    }
   ],
   "source": [
    "#fit the model \n",
    "history = model.fit(X_train,y_train,validation_split=.2, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5219d51e-e758-44ce-bebf-7a2094615007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 379s 8s/step - loss: 0.4409 - accuracy: 0.8775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4408557415008545, 0.8774603009223938]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b96d8e-d604-448c-981e-75f19c81354d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a10ae-aa5b-44a3-8518-229031c64d8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "xFkkFsP4VF-i",
    "outputId": "deed14d1-d047-4449-eb07-e38bfd0886dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show accuracy graphs from model\n",
    "acc = history.history['accuracy']\n",
    "val = history.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    " \n",
    "plt.plot(epochs, acc, '-', label='Training accuracy')\n",
    "plt.plot(epochs, val, ':', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "HoeeZjFn-oSl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HoeeZjFn-oSl",
    "outputId": "c2da680e-c9f6-4153-8a6e-ceea4dbc4dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Cabernet Sauvignon\n"
     ]
    }
   ],
   "source": [
    "#testing out the prediction with tasting notes and decoding prediction with dictionary mapping\n",
    "ans = model.predict(['cherry and tobacco'])\n",
    "idx = np.argmax(ans)\n",
    "print(mapping[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d3fdd-0f2f-4e8c-a2d3-00fcecb71e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to reload in the streamlit app\n",
    "#model.save('/content/gdrive/MyDrive/GA - DSIR 1010/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a267d45a-8da5-4f6d-9c29-dc9256f899fd",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec8b8d8-234a-4091-9a42-a253c229de8b",
   "metadata": {},
   "source": [
    "Overall, the BERT model increased accuracy by almost 10% from the Naive Bayes at a trade off of increased computing power and total memory needed to store the model for deployment. This was a great exercise but would definitly improve with more data. Ideally, all 400+ types of grapes could be identified and classifiied based on reviwes but it is beyond the scope and time constraints of the project. \n",
    "\n",
    "Improved text preprocessing could also help in the classification. Some data leakage occured since names of the grapes were mentioned within the review. Being able to remove this and focus on specific defining characteristics would help improve performance. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
